{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "Google_Gen_AI_Capstone_Project"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaJothi24/Google_GenAI/blob/main/Google_Capstone_Project_GeminiAPI_GenAI_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiModal AI Capablity *Image,Text,Video,Audio * understanding with Gemini"
      ],
      "metadata": {
        "id": "WMGdicu8PVD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image understanding with Gemini"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-13T11:06:42.216104Z",
          "iopub.execute_input": "2025-04-13T11:06:42.216407Z",
          "iopub.status.idle": "2025-04-13T11:06:42.220472Z",
          "shell.execute_reply.started": "2025-04-13T11:06:42.216385Z",
          "shell.execute_reply": "2025-04-13T11:06:42.219642Z"
        },
        "id": "H8ZdG5l7FebW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini has from the begining been a multimodal model, capable of analyzing all sorts of medias using its [long context window](https://developers.googleblog.com/en/new-features-for-the-gemini-api-and-google-ai-studio/).\n",
        "\n",
        "[Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) and later bring Image analysis to a whole new level as illustrated in [this image](https://i.pinimg.com/474x/c2/f7/52/c2f75236a0882c1e3dae641ae0fe6769.jpg):\n"
      ],
      "metadata": {
        "id": "3w14yjWnPVD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the image from the URL\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "display(Image(url=image_url))\n",
        "\n"
      ],
      "metadata": {
        "id": "CumMaR-sts53",
        "outputId": "73ed017b-4455-4745-a2fd-172e046aad70",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-13T11:08:45.989Z",
          "iopub.execute_input": "2025-04-13T11:08:45.989344Z",
          "iopub.status.idle": "2025-04-13T11:08:45.994918Z",
          "shell.execute_reply.started": "2025-04-13T11:08:45.98932Z",
          "shell.execute_reply": "2025-04-13T11:08:45.994282Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will show you how to easily use Gemini to perform the same kind of image, video and text analysis. Each of them has different prompts that you can select using the dropdown, also feel free to experiment with your own.\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "jexx9acnuDsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "This section install the SDK, set it up using  [API key](../quickstarts/Authentication.ipynb), imports the relevant libs, downloads the sample videos and upload them to Gemini.\n"
      ],
      "metadata": {
        "id": "R0HWzIEAQYqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install SDK\n",
        "\n",
        "The new **[Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/sdks)** provides programmatic access to Gemini 2.0 (and previous models) using both the [Google AI for Developers](https://ai.google.dev/gemini-api/docs) and [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) APIs. With a few exceptions, code that runs on one platform will run on both."
      ],
      "metadata": {
        "id": "UzBKAaL4QYq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q 'google-genai'"
      ],
      "metadata": {
        "id": "IbKkL5ksQYq1",
        "outputId": "a90fee26-8206-4d90-9a59-9209ec460ec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`."
      ],
      "metadata": {
        "id": "aDUGen_kQYq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call."
      ],
      "metadata": {
        "id": "_3Lez1vBQYq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the Gemini model\n",
        "\n",
        "Video understanding works best Gemini 2.5 pro model. Also select former models to compare their behavior but it is recommended to use at least the 2.0 ones.\n",
        "\n"
      ],
      "metadata": {
        "id": "ITgsQyaXQYq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gemini-2.5-pro-exp-03-25\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get sample iMAGEs\n",
        "\n",
        "I will start with uploaded image, as it's a more common use-case, but I will also see later to analyse Youtube videos."
      ],
      "metadata": {
        "id": "rv8ULT0lvJ47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to download and process image from URL\n",
        "def process_image_from_url(url):\n",
        "    try:\n",
        "        # Fetch the image data from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise error for bad response\n",
        "        image_data = BytesIO(response.content)\n",
        "\n",
        "        # Open the image using Pillow\n",
        "        image = Image.open(image_data)\n",
        "\n",
        "        # Example: Convert image to grayscale\n",
        "        grayscale_image = image.convert(\"L\")\n",
        "        grayscale_image.show()  # Display the processed image\n",
        "\n",
        "        # Save the processed image locally\n",
        "        grayscale_image.save(\"processed_image.jpg\")\n",
        "        print(\"Image processed and saved as 'processed_image.jpg'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "\n",
        "# Replace with your URL\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "process_image_from_url(image_url)\n"
      ],
      "metadata": {
        "id": "vDq7Gcbrfm2U",
        "outputId": "f8ffc51f-c9ff-4ec6-b857-bed5a0df94ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image processed and saved as 'processed_image.jpg'\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(file=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'image processing complete: ' + video_file.uri)\n",
        "\n",
        "  return video_file\n",
        "\n",
        "Image_analyse = upload_video('processed_image.jpg')\n"
      ],
      "metadata": {
        "id": "abZyD0ofg9kl",
        "outputId": "6031ae5c-1a24-44d7-e6cc-ffd2779c2199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image processing complete: https://generativelanguage.googleapis.com/v1beta/files/gdu13erdemka\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the image\n",
        "\n",
        "Upload  the image using the File API.\n",
        "\n",
        "This can take a couple of minutes as the videos will need to be processed and tokenized."
      ],
      "metadata": {
        "id": "Y4YMNQulz_yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown, HTML"
      ],
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the image\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "display(Image(url=image_url))\n"
      ],
      "metadata": {
        "id": "Cth2dDOJnMOd",
        "outputId": "11e49c34-a3ac-4f07-eb6b-673e2380a0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Describe the image in detail, focusing on the key objects, characters, and their interactions. Identify any notable patterns, colors, or themes present in the scene. Highlight the context or purpose of the elements within the image, and interpret the overall mood or message conveyed. Include any symbolic or cultural significance if applicable.\"\n",
        "\n",
        "video = \"processed_image.jpg\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)\n"
      ],
      "metadata": {
        "id": "PZw41-lsKKMf",
        "outputId": "f3a9c0af-c1cf-428a-9bf3-0fe659bd660a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here is a detailed description of the image `processed_image.jpg`:\n\n**Overall Impression:**\nThe image is a close-up to medium shot portrait of a woman proudly displaying a framed certificate or award. The focus is clearly on the woman and the object she holds, suggesting a moment of recognition or achievement.\n\n**Key Character:**\nThe central figure is a woman, likely middle-aged or slightly older.\n*   **Appearance:** She has dark, possibly short or pulled-back hair. She is wearing thin-rimmed eyeglasses.\n*   **Attire:** She is dressed in a dark-colored top, possibly black or navy blue, which appears somewhat formal or professional (like a blouse or jacket).\n*   **Expression:** She has a pleasant, genuine smile and is looking directly towards the camera (or slightly off-camera), engaging the viewer. Her expression conveys happiness, pride, and satisfaction.\n\n**Key Object:**\nThe woman is holding a framed document with both hands, presenting it forward.\n*   **Frame:** The frame appears to be made of dark wood or a similar dark material (black or dark brown).\n*   **Document:** Inside the frame is a light-colored (likely white or off-white) paper, consistent with a certificate, diploma, or award plaque. Text is visible on the document, but it is illegible at this resolution. There might be a logo or seal, but details aren't clear.\n*   **Handling:** She holds it carefully and centrally in front of her torso, emphasizing its importance.\n\n**Setting and Background:**\nThe background is simple and non-distracting, ensuring the focus remains on the woman and her achievement.\n*   It appears to be an indoor setting.\n*   The backdrop is a plain, light-colored wall (perhaps beige, cream, or light grey), possibly slightly textured but largely out of focus due to a shallow depth of field.\n*   The lighting seems adequate, likely indoor or possibly flash photography, illuminating the subject clearly without harsh shadows.\n\n**Interactions:**\n*   The primary interaction is between the woman and the implied viewer/camera. Her direct gaze and smile create a connection.\n*   She is interacting with the framed certificate by holding and displaying it prominently, signifying its value to her.\n\n**Patterns, Colors, and Themes:**\n*   **Patterns:** No strong visual patterns dominate, other than the simple rectangular shape of the frame and certificate.\n*   **Colors:** The color palette is relatively simple and muted: dark tones from her clothing and the frame contrast with the light certificate paper and the neutral background. Her skin tone and hair color add warmth.\n*   **Themes:** The prominent themes are achievement, recognition, pride, success, and celebration. It captures a milestone or moment of accomplishment.\n\n**Context and Purpose:**\n*   **Context:** The scene strongly suggests an award ceremony, a graduation, a recognition event, or a similar formal occasion where accomplishments are acknowledged and celebrated.\n*   **Purpose:** The purpose of the photograph is likely to document and commemorate this specific achievement. The woman is the recipient, and the certificate is the tangible evidence of her success.\n\n**Overall Mood and Message:**\nThe mood is positive, celebratory, and proud. The image conveys a clear message of personal or professional success and the satisfaction that comes with recognition for one's efforts or contributions.\n\n**Symbolic/Cultural Significance:**\n*   Framed certificates and awards are widely recognized symbols of validation, competence, and accomplishment within many cultures and professional/academic fields.\n*   The act of receiving and displaying such an item often carries cultural weight, signifying honor, merit, and the successful completion of a task, course, or period of service. The formal presentation (holding it carefully, smiling) reinforces the cultural value placed on such recognition.\n\nIn summary, the photograph captures a happy and proud woman displaying a framed certificate, symbolizing a significant moment of personal or professional achievement within a formal or celebratory context."
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract and organize text\n",
        "\n",
        "Gemini can also read what's in the .csv file and extract it in an organized way. Gemini reasoning capabilities can generate new ideas for you.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wog32E7CKnT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_csv_from_url(url):\n",
        "    try:\n",
        "        # Fetch the CSV data from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for unsuccessful requests\n",
        "\n",
        "        # Save the CSV content locally (optional)\n",
        "        with open(\"downloaded_file.csv\", \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "\n",
        "        # Load the CSV into a Pandas DataFrame\n",
        "        df = pd.read_csv(\"downloaded_file.csv\")\n",
        "\n",
        "        # Example Analysis: Display basic information about the data\n",
        "        print(\"First 5 rows:\")\n",
        "        print(df.head())\n",
        "\n",
        "        print(\"\\nSummary Statistics:\")\n",
        "        print(df.describe())\n",
        "\n",
        "        print(\"\\nColumns in the CSV file:\")\n",
        "        print(df.columns)\n",
        "\n",
        "        # You can add further analysis depending on your requirements\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "\n",
        "# Replace with your CSV URL\n",
        "csv_url = \"https://raw.githubusercontent.com/VijayaJothi24/VijayaJothi24/main/City.csv\"\n",
        "\n",
        "analyze_csv_from_url(csv_url)\n"
      ],
      "metadata": {
        "id": "baNCeA3GKrfu",
        "outputId": "75d19b81-48a3-422f-b84d-27be23460462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "               City Population    Users\n",
            "0       NEW YORK NY  8,405,837  302,149\n",
            "1  SAN FRANCISCO CA    629,591  213,609\n",
            "2        CHICAGO IL  1,955,130  164,468\n",
            "3    LOS ANGELES CA  1,595,037  144,132\n",
            "4     WASHINGTON DC    418,859  127,001\n",
            "\n",
            "Summary Statistics:\n",
            "               City Population    Users\n",
            "count            20         20       20\n",
            "unique           20         20       20\n",
            "top     NEW YORK NY  8,405,837  302,149\n",
            "freq              1          1        1\n",
            "\n",
            "Columns in the CSV file:\n",
            "Index(['City', 'Population', 'Users'], dtype='object')\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, Gemini is able to grasp to with item corresponds each note, including the last one."
      ],
      "metadata": {
        "id": "Zsh6i-Z6VHNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze youtube videos\n",
        "\n",
        "Downbelow Another Generative AI capablity task of Video Analysing is done"
      ],
      "metadata": {
        "id": "TEYYemjyKcZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"Find all the instances where Vijaya says \\\"software testing\\\". Provide timestamps and broader context for each instance.\"),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=13TBF_4KqXA')\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)\n"
      ],
      "metadata": {
        "id": "DP0Dd0hJKvYm",
        "outputId": "f6061f49-077d-4ca7-9a48-da261a17696d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the audio, here are the instances where Vijaya says \"software testing\", along with timestamps and context:\n\n1.  **Timestamp:** 0:05 - 0:07\n    *   **Context:** Vijaya is introducing the mind map shown on the screen. She says, \"...this is the screen for the **software testing** foundation...\" setting the overall topic of the presentation.\n\n2.  **Timestamp:** 1:09 - 1:11\n    *   **Context:** Vijaya is defining the term 'Defect' as presented in the mind map. She reads or explains the definition: \"An Error Identified in **Software Testing**.\"\n\n3.  **Timestamp:** 1:32 - 1:34\n    *   **Context:** After explaining a specific root cause example for a defect (incorrect GPS configuration), Vijaya mentions how such a defect would be discovered, stating, \"...So it is found during a **software testing**.\"\n\n4.  **Timestamp:** 3:15 - 3:17\n    *   **Context:** Vijaya is discussing the \"Value of Static testing\" and explaining why it's important. She concludes the point by saying, \"...This states the necessity of static testing in the **software testing** environment.\""
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12
    }
  ]
}