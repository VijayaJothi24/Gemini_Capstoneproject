{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaJothi24/Gemini_Capstoneproject/blob/main/Google_Gen_AI_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiModal AI Capablity *Image,Text,Video,Audio * understanding with Gemini"
      ],
      "metadata": {
        "id": "WMGdicu8PVD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image understanding with Gemini"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-13T11:06:42.216104Z",
          "iopub.execute_input": "2025-04-13T11:06:42.216407Z",
          "iopub.status.idle": "2025-04-13T11:06:42.220472Z",
          "shell.execute_reply.started": "2025-04-13T11:06:42.216385Z",
          "shell.execute_reply": "2025-04-13T11:06:42.219642Z"
        },
        "id": "H8ZdG5l7FebW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini has from the begining been a multimodal model, capable of analyzing all sorts of medias using its [long context window](https://developers.googleblog.com/en/new-features-for-the-gemini-api-and-google-ai-studio/).\n",
        "\n",
        "[Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) and later bring Image analysis to a whole new level as illustrated in [this image](https://i.pinimg.com/474x/c2/f7/52/c2f75236a0882c1e3dae641ae0fe6769.jpg):\n"
      ],
      "metadata": {
        "id": "3w14yjWnPVD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the image from the URL\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "display(Image(url=image_url))\n",
        "\n"
      ],
      "metadata": {
        "id": "CumMaR-sts53",
        "outputId": "944bc23c-6556-4516-9efd-4812100161e2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-13T11:08:45.989Z",
          "iopub.execute_input": "2025-04-13T11:08:45.989344Z",
          "iopub.status.idle": "2025-04-13T11:08:45.994918Z",
          "shell.execute_reply.started": "2025-04-13T11:08:45.98932Z",
          "shell.execute_reply": "2025-04-13T11:08:45.994282Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "This section install the SDK, set it up using  [API key](../quickstarts/Authentication.ipynb), imports the relevant libs, downloads the sample videos and upload them to Gemini.\n"
      ],
      "metadata": {
        "id": "R0HWzIEAQYqz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k63q0WeGosXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install SDK\n",
        "\n",
        "The new **[Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/sdks)** provides programmatic access to Gemini 2.0 (and previous models) using both the [Google AI for Developers](https://ai.google.dev/gemini-api/docs) and [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) APIs. With a few exceptions, code that runs on one platform will run on both."
      ],
      "metadata": {
        "id": "UzBKAaL4QYq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q 'google-genai'"
      ],
      "metadata": {
        "id": "IbKkL5ksQYq1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup  API key\n",
        "\n",
        "To run the following cell,  API key is stored it in a Colab Secret named `GOOGLE_API_KEY`."
      ],
      "metadata": {
        "id": "aDUGen_kQYq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call."
      ],
      "metadata": {
        "id": "_3Lez1vBQYq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the Gemini model\n",
        "\n",
        "Video understanding works best Gemini 2.5 pro model. Also select former models to compare their behavior but it is recommended to use at least the 2.0 ones.\n",
        "\n"
      ],
      "metadata": {
        "id": "ITgsQyaXQYq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gemini-2.5-pro-exp-03-25\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get sample Image\n",
        "\n",
        "I will start with uploaded image, as it's a more common use-case, but I will also see later to analyse Youtube videos."
      ],
      "metadata": {
        "id": "rv8ULT0lvJ47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to download and process image from URL\n",
        "def process_image_from_url(url):\n",
        "    try:\n",
        "        # Fetch the image data from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise error for bad response\n",
        "        image_data = BytesIO(response.content)\n",
        "\n",
        "        # Open the image using Pillow\n",
        "        image = Image.open(image_data)\n",
        "\n",
        "        # Example: Convert image to grayscale\n",
        "        grayscale_image = image.convert(\"L\")\n",
        "        grayscale_image.show()  # Display the processed image\n",
        "\n",
        "        # Save the processed image locally\n",
        "        grayscale_image.save(\"processed_image.jpg\")\n",
        "        print(\"Image processed and saved as 'processed_image.jpg'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "\n",
        "# Replace with your URL\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "process_image_from_url(image_url)\n"
      ],
      "metadata": {
        "id": "vDq7Gcbrfm2U",
        "outputId": "1c08abdf-8767-4275-8d11-88e3516f5dac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image processed and saved as 'processed_image.jpg'\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(file=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'image processing complete: ' + video_file.uri)\n",
        "\n",
        "  return video_file\n",
        "\n",
        "Image_analyse = upload_video('processed_image.jpg')\n"
      ],
      "metadata": {
        "id": "abZyD0ofg9kl",
        "outputId": "18dc5711-f193-470a-e249-ff61ca79183e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image processing complete: https://generativelanguage.googleapis.com/v1beta/files/4aaq5y2eoa8i\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the image\n",
        "\n",
        "Upload  the image using the File API.\n",
        "\n",
        "This can take a couple of minutes as the videos will need to be processed and tokenized."
      ],
      "metadata": {
        "id": "Y4YMNQulz_yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown, HTML"
      ],
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the image\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "display(Image(url=image_url))\n"
      ],
      "metadata": {
        "id": "Cth2dDOJnMOd",
        "outputId": "c8eb4362-e448-468f-bef8-fe169bb5b034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Describe the image in detail, focusing on the key shapes, color. Identify any notable patterns, colors, or themes preacters, analyze the elements and composition of this image. Describe the shapes, colors, arrangement, and any notable patterns or featuresHighlight the context or purpose of the elements within the image, and interpret the overall mood or message conveyed. Include any symbolic or cultural significance if applicable.\"\n",
        "\n",
        "video = \"processed_image.jpg\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)\n"
      ],
      "metadata": {
        "id": "PZw41-lsKKMf",
        "outputId": "1fb9a0e0-c1b8-4712-ce2c-9af261064fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's analyze the provided image, \"processed_image.jpg\".\n\n**Overall Impression:**\n\nThe image presents a vibrant and dynamic abstract composition characterized by geometric complexity and a striking color palette. It appears digitally generated or heavily processed, emphasizing clean lines, overlapping forms, and a sense of layered depth.\n\n**Shapes:**\n\n*   **Dominant Shapes:** The composition is built primarily from geometric shapes. Rectangles and squares form foundational blocks, often layered or intersecting. Sharp, angular triangles and diagonal lines cut across these steadier forms, introducing energy and movement.\n*   **Secondary Shapes:** Curved elements or partial circles might be present, offering a visual counterpoint to the prevailing angularity, softening edges, or creating focal points.\n*   **Interaction:** Shapes overlap extensively, creating new, composite forms in the intersections. Some shapes have crisp, well-defined edges, while others might have softer, blurred, or gradient transitions, suggesting varying depths or focal planes.\n\n**Colors:**\n\n*   **Palette:** The color palette is a key feature, likely high-contrast and saturated. Expect to see bold primary or secondary colors (like electric blues, vibrant reds or magentas, bright yellows or greens) juxtaposed against each other or against darker neutrals (deep grays, blacks) or stark whites.\n*   **Application:** Colors are likely applied in solid blocks corresponding to the geometric shapes. However, there might also be areas of gradient color transitions within shapes or subtle textural variations adding visual interest.\n*   **Contrast:** Strong value contrast (light vs. dark) and hue contrast (complementary or disparate colors placed side-by-side) are probably used to make the shapes pop and create visual excitement.\n\n**Arrangement and Composition:**\n\n*   **Layering:** The elements are arranged in multiple layers, creating a sense of depth and complexity. Some shapes appear closer, overlapping those behind them.\n*   **Balance:** The composition is likely asymmetrical, achieving balance through the careful distribution of visual weight (size, color intensity, placement of shapes) rather than mirroring.\n*   **Movement:** Diagonal lines, sharp angles, and the juxtaposition of contrasting elements likely create a strong sense of dynamism and visual movement, guiding the eye through the composition.\n*   **Focal Point:** While abstract, there might be a primary focal area where colors are brightest, shapes are most complex, or lines converge, drawing the viewer's initial attention.\n\n**Notable Patterns and Features:**\n\n*   **Repetition (Potential):** There might be repetition of certain shapes, colors, or motifs, creating rhythm or pattern within the overall complexity.\n*   **Intersection Effects:** The areas where shapes overlap might feature unique colors (as if through transparent layers) or distinct boundary lines, highlighting the layering process.\n*   **Digital Aesthetic:** The clean lines, potentially perfect geometric forms, and vibrant, possibly unnatural colors strongly suggest a digital origin or heavy digital manipulation (\"processed\"). There might be subtle digital artifacts or textures if examined closely.\n\n**Context and Purpose:**\n\n*   **Aesthetic Exploration:** The primary purpose appears to be aesthetic – an exploration of form, color, and composition. It functions as a piece of abstract visual art.\n*   **Graphic Design:** It could serve as a background element, a visual identity component (like for a tech company or creative agency), or an illustration demonstrating modern design principles.\n*   **Mood Board/Inspiration:** It might represent a visual theme or mood, perhaps related to technology, energy, urban environments, or complexity.\n\n**Overall Mood and Message:**\n\n*   **Mood:** The mood is likely energetic, dynamic, modern, and possibly complex or even slightly chaotic due to the layering and sharp angles. The vibrant colors contribute to a sense of excitement and intensity.\n*   **Message:** The image could be interpreted as representing the complexity of modern life, the interconnectedness of systems, the dynamism of technology, or simply the beauty found in structured abstraction. It celebrates geometry, color interaction, and digital precision.\n\n**Symbolic or Cultural Significance:**\n\n*   **Modernity/Technology:** Abstract geometric art, especially with a digital aesthetic, is often associated with modernity, technology, data, and progress.\n*   **Order and Chaos:** The interplay between structured geometric forms (order) and their complex, layered, sometimes jarring arrangement (chaos) can be seen as a visual metaphor for various systems or experiences.\n*   **Color Symbolism:** Specific colors might carry cultural associations (e.g., red for energy/passion, blue for stability/technology, yellow for optimism), though in abstract art, their primary role is often compositional and perceptual.\n\nIn summary, \"processed_image.jpg\" is likely a visually striking abstract piece dominated by layered geometric shapes, a vibrant and high-contrast color palette, and a dynamic composition. Its purpose is primarily aesthetic, conveying a mood of modern energy and complexity, potentially serving as digital art or a graphic design element."
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract and organize text\n",
        "\n",
        "Gemini can also read what's in the .csv file and extract it in an organized way. Gemini reasoning capabilities can generate new ideas for you.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wog32E7CKnT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_csv_from_url(url):\n",
        "    try:\n",
        "        # Fetch the CSV data from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for unsuccessful requests\n",
        "\n",
        "        # Save the CSV content locally (optional)\n",
        "        with open(\"downloaded_file.csv\", \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "\n",
        "        # Load the CSV into a Pandas DataFrame\n",
        "        df = pd.read_csv(\"downloaded_file.csv\")\n",
        "\n",
        "        # Example Analysis: Display basic information about the data\n",
        "        print(\"First 5 rows:\")\n",
        "        print(df.head())\n",
        "\n",
        "        print(\"\\nSummary Statistics:\")\n",
        "        print(df.describe())\n",
        "\n",
        "        print(\"\\nColumns in the CSV file:\")\n",
        "        print(df.columns)\n",
        "\n",
        "        # You can add further analysis depending on your requirements\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "\n",
        "# Replace with your CSV URL\n",
        "csv_url = \"https://raw.githubusercontent.com/VijayaJothi24/VijayaJothi24/main/City.csv\"\n",
        "\n",
        "analyze_csv_from_url(csv_url)\n"
      ],
      "metadata": {
        "id": "baNCeA3GKrfu",
        "outputId": "75d19b81-48a3-422f-b84d-27be23460462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "               City Population    Users\n",
            "0       NEW YORK NY  8,405,837  302,149\n",
            "1  SAN FRANCISCO CA    629,591  213,609\n",
            "2        CHICAGO IL  1,955,130  164,468\n",
            "3    LOS ANGELES CA  1,595,037  144,132\n",
            "4     WASHINGTON DC    418,859  127,001\n",
            "\n",
            "Summary Statistics:\n",
            "               City Population    Users\n",
            "count            20         20       20\n",
            "unique           20         20       20\n",
            "top     NEW YORK NY  8,405,837  302,149\n",
            "freq              1          1        1\n",
            "\n",
            "Columns in the CSV file:\n",
            "Index(['City', 'Population', 'Users'], dtype='object')\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, Gemini is able to grasp to with item corresponds each note, including the last one."
      ],
      "metadata": {
        "id": "Zsh6i-Z6VHNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze youtube videos\n",
        "\n",
        "Downbelow Another Generative AI capablity task of Video Analysing is done"
      ],
      "metadata": {
        "id": "TEYYemjyKcZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"Find all the instances where Vijaya says \\\"software testing\\\". Provide timestamps and broader context for each instance.\"),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri=https://www.youtube.com/watch?v=2HngmLk_W5A)\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)\n"
      ],
      "metadata": {
        "id": "DP0Dd0hJKvYm",
        "outputId": "f6061f49-077d-4ca7-9a48-da261a17696d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the audio, here are the instances where Vijaya says \"software testing\", along with timestamps and context:\n\n1.  **Timestamp:** 0:05 - 0:07\n    *   **Context:** Vijaya is introducing the mind map shown on the screen. She says, \"...this is the screen for the **software testing** foundation...\" setting the overall topic of the presentation.\n\n2.  **Timestamp:** 1:09 - 1:11\n    *   **Context:** Vijaya is defining the term 'Defect' as presented in the mind map. She reads or explains the definition: \"An Error Identified in **Software Testing**.\"\n\n3.  **Timestamp:** 1:32 - 1:34\n    *   **Context:** After explaining a specific root cause example for a defect (incorrect GPS configuration), Vijaya mentions how such a defect would be discovered, stating, \"...So it is found during a **software testing**.\"\n\n4.  **Timestamp:** 3:15 - 3:17\n    *   **Context:** Vijaya is discussing the \"Value of Static testing\" and explaining why it's important. She concludes the point by saying, \"...This states the necessity of static testing in the **software testing** environment.\""
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": null
    }
  ]
}