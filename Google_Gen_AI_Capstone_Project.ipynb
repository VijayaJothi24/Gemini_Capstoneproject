{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaJothi24/Gemini_Capstoneproject/blob/main/Google_Gen_AI_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiModal AI Capablity *Image,Text,Video,Audio * understanding with Gemini"
      ],
      "metadata": {
        "id": "WMGdicu8PVD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image understanding with Gemini"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-13T11:06:42.216104Z",
          "iopub.execute_input": "2025-04-13T11:06:42.216407Z",
          "iopub.status.idle": "2025-04-13T11:06:42.220472Z",
          "shell.execute_reply.started": "2025-04-13T11:06:42.216385Z",
          "shell.execute_reply": "2025-04-13T11:06:42.219642Z"
        },
        "id": "H8ZdG5l7FebW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini has from the begining been a multimodal model, capable of analyzing all sorts of medias using its [long context window](https://developers.googleblog.com/en/new-features-for-the-gemini-api-and-google-ai-studio/).\n",
        "\n",
        "[Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) and later bring Image analysis to a whole new level as illustrated in [this image](https://i.pinimg.com/474x/c2/f7/52/c2f75236a0882c1e3dae641ae0fe6769.jpg):\n"
      ],
      "metadata": {
        "id": "3w14yjWnPVD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the image from the URL\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "display(Image(url=image_url))\n",
        "\n"
      ],
      "metadata": {
        "id": "CumMaR-sts53",
        "outputId": "20cf9b39-1c55-4ccf-e61c-f0ff822372fb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-13T11:08:45.989Z",
          "iopub.execute_input": "2025-04-13T11:08:45.989344Z",
          "iopub.status.idle": "2025-04-13T11:08:45.994918Z",
          "shell.execute_reply.started": "2025-04-13T11:08:45.98932Z",
          "shell.execute_reply": "2025-04-13T11:08:45.994282Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 55
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "This section install the SDK, set it up using  [API key](../quickstarts/Authentication.ipynb), imports the relevant libs, downloads the sample videos and upload them to Gemini.\n"
      ],
      "metadata": {
        "id": "R0HWzIEAQYqz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k63q0WeGosXu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install SDK\n",
        "\n",
        "The new **[Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/sdks)** provides programmatic access to Gemini 2.0 (and previous models) using both the [Google AI for Developers](https://ai.google.dev/gemini-api/docs) and [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) APIs. With a few exceptions, code that runs on one platform will run on both."
      ],
      "metadata": {
        "id": "UzBKAaL4QYq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q 'google-genai'"
      ],
      "metadata": {
        "id": "IbKkL5ksQYq1"
      },
      "outputs": [],
      "execution_count": 56
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup  API key\n",
        "\n",
        "To run the following cell,  API key is stored it in a Colab Secret named `GOOGLE_API_KEY`."
      ],
      "metadata": {
        "id": "aDUGen_kQYq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "execution_count": 57
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call."
      ],
      "metadata": {
        "id": "_3Lez1vBQYq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "execution_count": 58
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the Gemini model\n",
        "\n",
        "Video understanding works best Gemini 2.5 pro model. Also select former models to compare their behavior but it is recommended to use at least the 2.0 ones.\n",
        "\n"
      ],
      "metadata": {
        "id": "ITgsQyaXQYq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gemini-2.5-pro-exp-03-25\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "execution_count": 59
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get sample Image\n",
        "\n",
        "I will start with uploaded image, as it's a more common use-case, but I will also see later to analyse Youtube videos."
      ],
      "metadata": {
        "id": "rv8ULT0lvJ47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to download and process image from URL\n",
        "def process_image_from_url(url):\n",
        "    try:\n",
        "        # Fetch the image data from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise error for bad response\n",
        "        image_data = BytesIO(response.content)\n",
        "\n",
        "        # Open the image using Pillow\n",
        "        image = Image.open(image_data)\n",
        "\n",
        "        # Example: Convert image to grayscale\n",
        "        grayscale_image = image.convert(\"L\")\n",
        "        grayscale_image.show()  # Display the processed image\n",
        "\n",
        "        # Save the processed image locally\n",
        "        grayscale_image.save(\"processed_image.jpg\")\n",
        "        print(\"Image processed and saved as 'processed_image.jpg'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "\n",
        "# Replace with your URL\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "process_image_from_url(image_url)\n"
      ],
      "metadata": {
        "id": "vDq7Gcbrfm2U",
        "outputId": "441fd0aa-947d-403f-b9ee-2bb43b06a4cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image processed and saved as 'processed_image.jpg'\n"
          ]
        }
      ],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(file=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'image processing complete: ' + video_file.uri)\n",
        "\n",
        "  return video_file\n",
        "\n",
        "Image_analyse = upload_video('processed_image.jpg')\n"
      ],
      "metadata": {
        "id": "abZyD0ofg9kl",
        "outputId": "f06d4bee-bc54-462b-c112-5c00f7474cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image processing complete: https://generativelanguage.googleapis.com/v1beta/files/paoy1x4n0hyf\n"
          ]
        }
      ],
      "execution_count": 61
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the image\n",
        "\n",
        "Upload  the image using the File API.\n",
        "\n",
        "This can take a couple of minutes as the videos will need to be processed and tokenized."
      ],
      "metadata": {
        "id": "Y4YMNQulz_yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown, HTML"
      ],
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "execution_count": 62
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the image\n",
        "image_url = \"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"\n",
        "display(Image(url=image_url))\n"
      ],
      "metadata": {
        "id": "Cth2dDOJnMOd",
        "outputId": "422359e8-dbb5-4c97-9fc7-0f70a705bdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/736x/20/2a/fe/202afe2d2615248f757fa0e4d925d701.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 63
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Describe the image in detail, focusing on the key shapes, color. Identify any notable patterns, colors, or themes preacters, analyze the elements and composition of this image. Describe the shapes, colors, arrangement, and any notable patterns or featuresHighlight the context or purpose of the elements within the image, and interpret the overall mood or message conveyed. Include any symbolic or cultural significance if applicable.\"\n",
        "\n",
        "video = \"processed_image.jpg\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)\n"
      ],
      "metadata": {
        "id": "PZw41-lsKKMf",
        "outputId": "8535ca31-d900-4e62-8253-9c73c122d38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's break down the image `processed_image.jpg`.\n\nSince I cannot directly *see* the image you're referring to (`processed_image.jpg`), I will provide a **hypothetical description** based on what such a filename often implies. Images labeled \"processed\" are frequently altered digitally, leading to possibilities like:\n\n1.  **Abstract Digital Art:** Generated or heavily manipulated for aesthetic effect.\n2.  **Enhanced Photograph:** A photo with significantly adjusted colors, contrast, textures, or added effects.\n3.  **Scientific/Data Visualization:** Data represented visually, often with distinct colors and shapes.\n4.  **Graphic Design Element:** An asset created for use in larger designs.\n\n**I will structure the description assuming it's likely an abstract or heavily stylized visual.**\n\n---\n\n**Hypothetical Description of \"processed_image.jpg\":**\n\n**Overall Impression:**\nThe image presents a vibrant and dynamic abstract composition, clearly having undergone significant digital processing. It feels energetic and contemporary, possibly exploring themes of technology, data flow, or pure aesthetic form.\n\n**Shapes:**\nThe composition is likely dominated by a mix of **geometric and organic shapes**. We might see sharp, angular forms like triangles, rectangles, or shards intersecting with softer, flowing curves or amorphous blobs. There could be distinct **linear elements** â€“ perhaps thin, glowing lines tracing paths across the canvas, or thicker vector-like strokes defining boundaries. The edges between shapes might range from crisp and defined to soft and blurred, indicating layering or effects like gradients and glows.\n\n**Colors:**\nThe color palette is probably a key feature, likely **bold and saturated**. We might observe:\n*   **Dominant Hues:** Perhaps a foundation of cool colors like deep blues, cyans, or purples, suggesting a digital or futuristic theme.\n*   **Accent Colors:** Contrasting, high-energy accents like electric pink, bright orange, or neon green could be used to draw attention to focal points or create visual tension.\n*   **Gradients & Blending:** Colors might not be flat but could transition smoothly through gradients, or blend where shapes overlap, creating complex intermediate hues.\n*   **Luminosity:** Some elements might appear to glow or emit light, achieved through bright highlights or simulated bloom effects.\n\n**Arrangement & Composition:**\nThe elements are likely arranged **asymmetrically**, creating a sense of movement and dynamism rather than static balance. There might be a clear **focal point** where colors are brightest or shapes are most complex, drawing the viewer's eye. **Layering** is probably evident, with shapes overlapping to create depth. The composition might guide the eye along diagonals or curves across the image space. The overall structure could feel complex, perhaps even bordering on chaotic, yet retaining an underlying sense of design or order.\n\n**Patterns & Textures:**\nWhile potentially smooth overall due to digital creation, there might be **subtle textures or patterns** applied. This could include:\n*   **Digital Noise/Grain:** A fine texture added for effect.\n*   **Scan Lines or Glitch Effects:** Suggesting a digital origin or malfunction.\n*   **Repeating Motifs:** Small geometric patterns embedded within larger shapes.\n*   **Simulated Surfaces:** Areas might mimic glossy plastic, brushed metal, or soft light diffusion.\n\n**Context & Purpose:**\nGiven its \"processed\" nature, the image likely serves an aesthetic or illustrative purpose. It could be:\n*   **Digital Art:** Created purely for visual appeal.\n*   **Background Element:** For a website, presentation, or graphic design project.\n*   **Conceptual Illustration:** Representing abstract ideas like data networks, energy, artificial intelligence, or creative processes.\n*   **Promotional Material:** For a tech product, event, or brand emphasizing innovation.\n\n**Mood & Message:**\nThe overall mood is likely **energetic, modern, and possibly intense**. The use of vibrant colors and dynamic shapes often conveys excitement, innovation, complexity, or transformation. Depending on the specific color palette and forms, it could also feel futuristic, synthetic, or even slightly overwhelming. The message might be about the beauty of digital creation, the complexity of modern systems, or simply an exploration of form and color.\n\n**Symbolic/Cultural Significance:**\nDirect symbolism would depend heavily on the specific shapes and colors used. However:\n*   **Abstract forms** generally avoid literal representation, inviting subjective interpretation.\n*   **Bright, artificial colors and sharp lines** often culturally signify technology, the future, and urban environments.\n*   **Flowing lines and organic shapes** might represent nature, data flow, or more human elements within a technological context.\n*   The very act of **\"processing\"** can symbolize human intervention, transformation, or the creation of something new from raw data or source material.\n\n---\n\n**To give you a more accurate description, I would need to actually see the image.** Please provide the image if possible!"
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "execution_count": 64
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract and organize text\n",
        "\n",
        "Gemini can also read what's in the .csv file and extract it in an organized way. Gemini reasoning capabilities can generate new ideas for you.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wog32E7CKnT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_csv_from_url(url):\n",
        "    try:\n",
        "        # Fetch the CSV data from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for unsuccessful requests\n",
        "\n",
        "        # Save the CSV content locally (optional)\n",
        "        with open(\"downloaded_file.csv\", \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "\n",
        "        # Load the CSV into a Pandas DataFrame\n",
        "        df = pd.read_csv(\"downloaded_file.csv\")\n",
        "\n",
        "        # Example Analysis: Display basic information about the data\n",
        "        print(\"First 5 rows:\")\n",
        "        print(df.head())\n",
        "\n",
        "        print(\"\\nSummary Statistics:\")\n",
        "        print(df.describe())\n",
        "\n",
        "        print(\"\\nColumns in the CSV file:\")\n",
        "        print(df.columns)\n",
        "\n",
        "        # You can add further analysis depending on your requirements\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "\n",
        "# Replace with your CSV URL\n",
        "csv_url = \"https://raw.githubusercontent.com/VijayaJothi24/VijayaJothi24/main/City.csv\"\n",
        "\n",
        "analyze_csv_from_url(csv_url)\n"
      ],
      "metadata": {
        "id": "baNCeA3GKrfu",
        "outputId": "c6ae0110-d05f-4331-e236-ea5338ea9093",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "               City Population    Users\n",
            "0       NEW YORK NY  8,405,837  302,149\n",
            "1  SAN FRANCISCO CA    629,591  213,609\n",
            "2        CHICAGO IL  1,955,130  164,468\n",
            "3    LOS ANGELES CA  1,595,037  144,132\n",
            "4     WASHINGTON DC    418,859  127,001\n",
            "\n",
            "Summary Statistics:\n",
            "               City Population    Users\n",
            "count            20         20       20\n",
            "unique           20         20       20\n",
            "top     NEW YORK NY  8,405,837  302,149\n",
            "freq              1          1        1\n",
            "\n",
            "Columns in the CSV file:\n",
            "Index(['City', 'Population', 'Users'], dtype='object')\n"
          ]
        }
      ],
      "execution_count": 65
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, Gemini is able to grasp to with item corresponds each note, including the last one."
      ],
      "metadata": {
        "id": "Zsh6i-Z6VHNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze youtube videos\n",
        "\n",
        "Downbelow Another Generative AI capablity task of Video Analysing is done"
      ],
      "metadata": {
        "id": "TEYYemjyKcZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"Find all the instances where Vijaya says \\\"software testing\\\". Provide timestamps and broader context for each instance.\"),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=13TBF_4KqXA')\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)\n"
      ],
      "metadata": {
        "id": "DP0Dd0hJKvYm",
        "outputId": "e8975c45-da9d-435f-f5e1-0319a71df989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here are the instances where Vijaya says \"software testing\", along with timestamps and context:\n\n1.  **Timestamp:** 0:06 - 0:07\n    *   **Quote:** \"...the screen for the **software testing** foundation...\"\n    *   **Context:** Vijaya is introducing the mind map shown on the screen. She states that the map represents the \"Software Testing foundation\" and is about to list the main points or topics covered within it.\n\n2.  **Timestamp:** 1:08 - 1:11\n    *   **Quote:** \"So defect is an error identified in **software testing**.\"\n    *   **Context:** Vijaya is defining the term \"Defect\" as shown on the mind map. She explains that a defect specifically refers to an error that is discovered during the process of software testing. She then provides a root cause example.\n\n3.  **Timestamp:** 1:31 - 1:34\n    *   **Quote:** \"So it is found during a **software testing**.\"\n    *   **Context:** Vijaya is explaining the root cause example for a defect (an incorrect configuration variable for a GPS function in a fitness tracker). She explicitly states that this particular defect was discovered during software testing activities.\n\n4.  **Timestamp:** 3:11 - 3:17\n    *   **Quote:** \"...This states the necessity of static testing in the **software testing** environment.\"\n    *   **Context:** Vijaya is discussing the \"Value of Static testing\". She explains that static analysis helped find coding faults they wouldn't have found otherwise with only dynamic testing, thereby demonstrating the importance or \"necessity\" of including static testing within the overall software testing process or environment."
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "execution_count": 66
    }
  ]
}